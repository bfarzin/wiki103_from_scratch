{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "import re\n",
    "import sentencepiece as spm #https://github.com/google/sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20190123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/home/farzin/rnn_python_code/wiki103_from_download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2G\t/home/farzin/rnn_python_code/wiki103_from_download/tmp_bwd\r\n",
      "1.2G\t/home/farzin/rnn_python_code/wiki103_from_download/tmp\r\n",
      "1.3G\t/home/farzin/rnn_python_code/wiki103_from_download/sp_tokenizer\r\n",
      "225M\t/home/farzin/rnn_python_code/wiki103_from_download/lm/lm_data\r\n",
      "861M\t/home/farzin/rnn_python_code/wiki103_from_download/lm/models\r\n",
      "1.1G\t/home/farzin/rnn_python_code/wiki103_from_download/lm\r\n",
      "225M\t/home/farzin/rnn_python_code/wiki103_from_download/lm_bwd/lm_data_bwd\r\n",
      "1.1G\t/home/farzin/rnn_python_code/wiki103_from_download/lm_bwd/models\r\n",
      "1.3G\t/home/farzin/rnn_python_code/wiki103_from_download/lm_bwd\r\n",
      "1.6G\t/home/farzin/rnn_python_code/wiki103_from_download/clas/models\r\n",
      "1.6G\t/home/farzin/rnn_python_code/wiki103_from_download/clas\r\n",
      "2.3G\t/home/farzin/rnn_python_code/wiki103_from_download/models\r\n",
      "906M\t/home/farzin/rnn_python_code/wiki103_from_download/clas_bwd/models\r\n",
      "906M\t/home/farzin/rnn_python_code/wiki103_from_download/clas_bwd\r\n",
      "11G\t/home/farzin/rnn_python_code/wiki103_from_download\r\n"
     ]
    }
   ],
   "source": [
    "!du -h {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/farzin/rnn_python_code/wiki103_from_download\u001b[00m\r\n",
      "├── \u001b[01;34mclas\u001b[00m\r\n",
      "│   └── \u001b[01;34mmodels\u001b[00m\r\n",
      "│       ├── final_FL.pth\r\n",
      "│       ├── final.pth\r\n",
      "│       ├── \u001b[01;36mfine_tuned_enc60kb.pth\u001b[00m -> ../../lm/models/fine_tuned_enc60kb.pth\r\n",
      "│       ├── second_FL.pth\r\n",
      "│       ├── second.pth\r\n",
      "│       ├── third_FL.pth\r\n",
      "│       ├── third.pth\r\n",
      "│       └── tmp.pth\r\n",
      "├── \u001b[01;34mclas_bwd\u001b[00m\r\n",
      "│   └── \u001b[01;34mmodels\u001b[00m\r\n",
      "│       ├── final_bwd.pth\r\n",
      "│       ├── \u001b[01;36mfine_tuned60kb_bwd.pth\u001b[00m -> ../../lm_bwd/models/fine_tuned60kb_bwd.pth\r\n",
      "│       ├── \u001b[01;36mfine_tuned_enc60kb_bwd.pth\u001b[00m -> ../../lm_bwd/models/fine_tuned_enc60kb_bwd.pth\r\n",
      "│       ├── second_bwd.pth\r\n",
      "│       ├── third_bwd.pth\r\n",
      "│       └── tmp.pth\r\n",
      "├── \u001b[01;34mlm\u001b[00m\r\n",
      "│   ├── \u001b[01;34mlm_data\u001b[00m\r\n",
      "│   │   ├── classes.txt\r\n",
      "│   │   ├── itos.pkl\r\n",
      "│   │   ├── train_ids.npy\r\n",
      "│   │   ├── train_lbl.npy\r\n",
      "│   │   ├── valid_ids.npy\r\n",
      "│   │   └── valid_lbl.npy\r\n",
      "│   └── \u001b[01;34mmodels\u001b[00m\r\n",
      "│       ├── fine_tuned60kb.pth\r\n",
      "│       ├── fine_tuned_enc60kb.pth\r\n",
      "│       ├── fit_head.pth\r\n",
      "│       ├── \u001b[01;36mitos_raw_spacy.pkl\u001b[00m -> ../../models/itos_raw_spacy.pkl\r\n",
      "│       ├── \u001b[01;36mtmp.pth\u001b[00m -> ../../models/tmp.pth\r\n",
      "│       ├── \u001b[01;36mwiki103_raw_articles_sentencepiece_20190123.pth\u001b[00m -> ../../models/wiki103_raw_articles_sentencepiece_20190123.pth\r\n",
      "│       ├── \u001b[01;36mwiki103_raw_articles_spacy_20190122.pth\u001b[00m -> ../../models/wiki103_raw_articles_spacy_20190122.pth\r\n",
      "│       ├── \u001b[01;36mwiki103_raw_articles_spacy_20190123.pth\u001b[00m -> ../../models/wiki103_raw_articles_spacy_20190123.pth\r\n",
      "│       ├── \u001b[01;36mwiki103_spacy_enc.pth\u001b[00m -> ../../models/wiki103_spacy_enc.pth\r\n",
      "│       └── \u001b[01;36mwiki103_sp_enc.pth\u001b[00m -> ../../models/wiki103_sp_enc.pth\r\n",
      "├── \u001b[01;34mlm_bwd\u001b[00m\r\n",
      "│   ├── \u001b[01;34mlm_data_bwd\u001b[00m\r\n",
      "│   │   ├── classes.txt\r\n",
      "│   │   ├── itos.pkl\r\n",
      "│   │   ├── train_ids.npy\r\n",
      "│   │   ├── train_lbl.npy\r\n",
      "│   │   ├── valid_ids.npy\r\n",
      "│   │   └── valid_lbl.npy\r\n",
      "│   └── \u001b[01;34mmodels\u001b[00m\r\n",
      "│       ├── fine_tuned60kb_bwd.pth\r\n",
      "│       ├── fine_tuned_enc60kb_bwd.pth\r\n",
      "│       ├── fit_head_bwd.pth\r\n",
      "│       ├── \u001b[01;36mitos_raw_spacy.pkl\u001b[00m -> ../../models/itos_raw_spacy.pkl\r\n",
      "│       ├── tmp.pth\r\n",
      "│       └── \u001b[01;36mwiki103_raw_articles_spacy_BWD_20190123.pth\u001b[00m -> ../../models/wiki103_raw_articles_spacy_BWD_20190123.pth\r\n",
      "├── \u001b[01;34mmodels\u001b[00m\r\n",
      "│   ├── itos_raw_spacy.pkl\r\n",
      "│   ├── tmp.pth\r\n",
      "│   ├── wiki103_raw_articles_sentencepiece_20190123.pth\r\n",
      "│   ├── wiki103_raw_articles_spacy_20190122.pth\r\n",
      "│   ├── wiki103_raw_articles_spacy_20190123.pth\r\n",
      "│   ├── wiki103_raw_articles_spacy_BWD_20190123.pth\r\n",
      "│   ├── wiki103_spacy_enc_BWD.pth\r\n",
      "│   ├── wiki103_spacy_enc.pth\r\n",
      "│   └── wiki103_sp_enc.pth\r\n",
      "├── \u001b[01;34msp_tokenizer\u001b[00m\r\n",
      "│   ├── classes.txt\r\n",
      "│   ├── itos.pkl\r\n",
      "│   ├── train_ids.npy\r\n",
      "│   ├── train_lbl.npy\r\n",
      "│   ├── valid_ids.npy\r\n",
      "│   └── valid_lbl.npy\r\n",
      "├── \u001b[01;34mtmp\u001b[00m\r\n",
      "│   ├── classes.txt\r\n",
      "│   ├── itos.pkl\r\n",
      "│   ├── train_ids.npy\r\n",
      "│   ├── train_lbl.npy\r\n",
      "│   ├── valid_ids.npy\r\n",
      "│   └── valid_lbl.npy\r\n",
      "└── \u001b[01;34mtmp_bwd\u001b[00m\r\n",
      "    ├── classes.txt\r\n",
      "    ├── itos.pkl\r\n",
      "    ├── train_ids.npy\r\n",
      "    ├── train_lbl.npy\r\n",
      "    ├── valid_ids.npy\r\n",
      "    └── valid_lbl.npy\r\n",
      "\r\n",
      "14 directories, 69 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull and prep IMDB data for supervised and unsupervised step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/farzin/.fastai/data/imdb')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_PATH = untar_data(URLs.IMDB)\n",
    "IMDB_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH = PATH/'clas'\n",
    "LM_PATH = PATH/'lm'\n",
    "os.makedirs(CLAS_PATH, exist_ok=True)\n",
    "os.makedirs(LM_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## raw data does not have the unsup in the train directory.  Just move it there\n",
    "#  ~/.fastai/data/imdb$ mv unsup/ ./train/\n",
    "CLASSES = ['neg', 'pos', 'unsup']\n",
    "\n",
    "def get_texts(path):\n",
    "    texts,labels,scores = [],[],[]\n",
    "    for idx,label in enumerate(CLASSES):\n",
    "        for fname in (path/label).glob('*.*'):\n",
    "            texts.append(fname.open('r', encoding='utf8').read())\n",
    "            labels.append(idx)\n",
    "            review_name = listify(fname.parts)[-1].split('.')[0]\n",
    "            scores.append( int(review_name.split(\"_\")[1]) )\n",
    "\n",
    "    return np.array(texts),np.array(labels),np.array(scores)\n",
    "\n",
    "train_texts,train_labels,train_scr = get_texts(IMDB_PATH/'train')\n",
    "valid_texts,valid_labels,valid_scr = get_texts(IMDB_PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 25000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts),len(valid_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.permutation(len(train_texts))\n",
    "valid_idx = np.random.permutation(len(valid_texts))\n",
    "\n",
    "train_texts,train_labels,train_scr = train_texts[train_idx],train_labels[train_idx],train_scr[train_idx]\n",
    "valid_texts,valid_labels,valid_scr = valid_texts[valid_idx],valid_labels[valid_idx],valid_scr[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'text':train_texts, 'labels':train_labels, 'rating':train_scr}, columns=['labels','text','rating'])\n",
    "valid_df = pd.DataFrame({'text':valid_texts, 'labels':valid_labels, 'rating':valid_scr}, columns=['labels','text','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5100\n",
      "4    2696\n",
      "3    2420\n",
      "2    2284\n",
      "Name: rating, dtype: int64\n",
      "10    4732\n",
      "8     3009\n",
      "7     2496\n",
      "9     2263\n",
      "Name: rating, dtype: int64\n",
      "0    50000\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for this_cls in range(3):\n",
    "    print(train_df[train_df.labels == this_cls]['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = np.concatenate([train_texts,valid_texts])\n",
    "idx = np.random.permutation(len(all_texts))\n",
    "cut = int(0.1 * len(idx))\n",
    "LM_train_df = pd.DataFrame({'text':all_texts[idx[cut:]], 'labels':[0] * (len(all_texts)-cut)}, columns=['labels','text'])\n",
    "LM_valid_df = pd.DataFrame({'text':all_texts[idx[:cut]], 'labels':[0] * cut}, columns=['labels','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 90000, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts),len(LM_train_df),len(LM_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Simply boring! This is one of the worst movies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>After you've watched The Love Bug, you will no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The third Muppet movie is perhaps the most rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A movie like the life - complex, with unexpect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I didn´t enjoy the film at all. Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       0  Simply boring! This is one of the worst movies...\n",
       "1       0  After you've watched The Love Bug, you will no...\n",
       "2       0  The third Muppet movie is perhaps the most rel...\n",
       "3       0  A movie like the life - complex, with unexpect...\n",
       "4       0  <br /><br />I didn´t enjoy the film at all. Th..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Another trashy Grade Z quickie from the prolif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This show stinks. For parents, they usually wa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Just two comments....SEVEN years apart? Hardly...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>SOME NOT-SO-SPOILY SPOILERS AHEAD&lt;br /&gt;&lt;br /&gt;W...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a very funny movie, easy to watch, tha...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels                                               text  rating\n",
       "0        0  Another trashy Grade Z quickie from the prolif...       1\n",
       "1        0  This show stinks. For parents, they usually wa...       2\n",
       "5        1  Just two comments....SEVEN years apart? Hardly...       7\n",
       "8        0  SOME NOT-SO-SPOILY SPOILERS AHEAD<br /><br />W...       4\n",
       "10       1  This is a very funny movie, easy to watch, tha...       7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS_train_df = train_df[train_df.labels != 2]\n",
    "CLS_valid_df = valid_df[valid_df.labels != 2]\n",
    "CLS_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer SpacyTokenizer in en with the following rules:\n",
       " - fixup\n",
       " - replace_rep\n",
       " - replace_wrep\n",
       " - deal_caps\n",
       " - spec_add_spaces\n",
       " - rm_useless_spaces\n",
       " - sub_br\n",
       " - replace_all_caps\n",
       " - deal_caps"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sub_br(t:str) -> str:\n",
    "    \"Replaces the <br /> by \\n\"\n",
    "    re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "    return re_br.sub(\"\\n\", t)\n",
    "\n",
    "def spec_add_spaces(t:str) -> str:\n",
    "    \"Add spaces between special characters\"\n",
    "    return re.sub(r'([/#])', r' \\1 ', t)\n",
    "\n",
    "def rm_useless_spaces(t:str) -> str:\n",
    "    \"Remove multiple spaces\"\n",
    "    return re.sub(' {2,}', ' ', t)\n",
    "\n",
    "def replace_rep(t:str) -> str:\n",
    "    \"Replace repetitions at the character level\"\n",
    "    def _replace_rep(m:Collection[str]) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_REP} {len(cc)+1} {c} '\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    return re_rep.sub(_replace_rep, t)\n",
    "    \n",
    "def replace_wrep(t:str) -> str:\n",
    "    \"Replace word repetitions\"\n",
    "    def _replace_wrep(m:Collection[str]) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_WREP} {len(cc.split())+1} {c} '\n",
    "    re_wrep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n",
    "    return re_wrep.sub(_replace_wrep, t)\n",
    "\n",
    "def deal_caps(t:str) -> str:\n",
    "    \"Replace words in all caps\"\n",
    "    res = []\n",
    "    for s in re.findall(r'\\w+|\\W+', t):\n",
    "        res += ([f' {TK_UP} ',s.lower()] if (s.isupper() and (len(s)>2)) else [s.lower()])\n",
    "    return ''.join(res)\n",
    "\n",
    "def fixup(x:str) -> str:\n",
    "    \"List of replacements from html strings\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "default_rules = [fixup, replace_rep, replace_wrep, deal_caps, spec_add_spaces, rm_useless_spaces, sub_br]\n",
    "default_spec_tok = [BOS, FLD, UNK, PAD]\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(pre_rules=default_rules, special_cases=[BOS, FLD, 'xxunk', 'xxpad'], n_cpus=4)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LM DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000 #can we make this the full possible vocab at 260k?\n",
    "\n",
    "keyword_args = {'max_vocab':max_vocab}\n",
    "imdb_data_lm = TextLMDataBunch.from_df(LM_PATH, LM_train_df, LM_valid_df, tokenizer=tokenizer,\n",
    "                               text_cols='text', label_cols='labels',**keyword_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_lm.save('lm_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finetune LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 140\n",
    "emb_sz,nh,nl = 400,1111,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(imdb_data_lm,bptt,emb_sz,nh,nl,drop_mult=0.5,qrnn=True, \n",
    "                               pretrained_fnames=['wiki103_raw_articles_spacy_20190123',\n",
    "                                                  'itos_raw_spacy'])\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7), wd=0.03, pct_start=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 1e-3, moms=(0.9,0.75), wd=0.01, pct_start=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned60kb')\n",
    "learn.save_encoder('fine_tuned_enc60kb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned60kb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build/train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Another trashy Grade Z quickie from the prolif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This show stinks. For parents, they usually wa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Just two comments....SEVEN years apart? Hardly...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>SOME NOT-SO-SPOILY SPOILERS AHEAD&lt;br /&gt;&lt;br /&gt;W...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a very funny movie, easy to watch, tha...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels                                               text  rating\n",
       "0        0  Another trashy Grade Z quickie from the prolif...       1\n",
       "1        0  This show stinks. For parents, they usually wa...       2\n",
       "5        1  Just two comments....SEVEN years apart? Hardly...       7\n",
       "8        0  SOME NOT-SO-SPOILY SPOILERS AHEAD<br /><br />W...       4\n",
       "10       1  This is a very funny movie, easy to watch, tha...       7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_clas = TextClasDataBunch.from_df(CLAS_PATH,CLS_train_df,CLS_valid_df, tokenizer=tokenizer,\n",
    "                                           vocab=imdb_data_lm.train_ds.vocab,label_cols='labels',text_cols='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learn\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos another trashy grade z quickie from the prolific albert pyun . tim xxunk 13 inch clint eastwood - like cop from outer space chases an ugly flying head ( ! ) to earth and gets involved in a gang war in south bronx ! mercifully short , but xxunk dull , with the cheesiest effects since attack of the 50 ft woman . they should have fired the continuity guy , too : note how xxunk sunglasses disappears and reappears in every second shot . laughably bad , but that´s why we watch these movies , xxunk it ? sequel ´ dollman vs. demonic toys ´ is reportedly even worse , if that´s possible . \n",
       "\n",
       " 0 ( of xxrep 4 * ) \n",
       "\n",
       ", Text xxbos this show stinks . for parents , they usually want their kids to watch something good for them . it is usually educational , funny , and bright . \n",
       "\n",
       " is it educational ? no . the doodlebops sing and that 's it . they usually sing about themselves , they do n't try teaching anything . \n",
       "\n",
       " is it funny ? no . the doodlebops instead say something which is not intended as a joke , and laugh at it . \n",
       "\n",
       " is it bright ? it 's so bright , it 's painful . as far as color , s everything is extremely bright , so that 's good . but xxup nothing is ever wrong in the world of the xxunk 's . therefore , they are always happy . a kid in trouble will become depressed because they have never been exposed to being sad . \n",
       "\n",
       " the show is also extremely cheesy . every syllable is said to the highest level of exaggeration and very corny . it 's overkill . \n",
       "\n",
       " for kids , it 's entertaining , but past the age of 2 you wo n't want your kids to see it . they 'll never know how to grow up ., Text xxbos just two comments xxrep 4 . xxup seven years apart ? hardly evidence of the film 's relentless pulling - power ! as has been mentioned , the low - budget telemovie status of 13 xxup gantry xxup row is a mitigating factor in its limited appeal . having said that however the thing is not without merit - either as entertainment or as a fright outing per se . \n",
       "\n",
       " true , the plot at its most basic is a re - working of xxup the xxup amityville xxup horror - only without much horror . more a case of intrigue ! gibney might have made a more worthwhile impression if she had played xxunk xxunk a couple of seemingly unconnected murders with the \" house \" as the main suspect . the script is better than average and the production overall of a high standard . it just fails to engage the viewer particularly at key moments . \n",
       "\n",
       " having picked the xxup dvd up for a mere $ xxunk last week at my regular video store , i can not begrudge the expenditure . $ xxunk would be an acceptable price for the film . just do n't expect fireworks !, Text xxbos xxup some xxup not - so- xxup xxunk xxup spoilers xxup ahead \n",
       "\n",
       " why do people , when they are disoriented or sick or scared at a club , cut through the middle of the crowded dance floor on their way to the bathroom ? \n",
       "\n",
       " who in their right mind would hide under a bed when someone breaks into their room ? \n",
       "\n",
       " how often do you knock on a stranger 's door and when they do n't xxup immediately answer , you open the door , walk in , shout a few hello 's and then start going through their stuff ? \n",
       "\n",
       " if you were being pursued by someone you just discovered was a murderer , what would you do ? quietly sneak off and hide under a wooden platform or among metal implements ? run , quietly of course , to a ratty old barn or other decrepit structure ? \n",
       "\n",
       " i could be talking about almost any thriller that 's come out in the last few years , but since this is the \" the return \" page , obviously i 'm talking about \" the return . \" i saw it free because i work at a movie theater and make a point of screening all the \" scary \" movies . i thought this one was tolerable ... aside from the well - worn clichés . sarah michelle gellar is really drab and looks kind of \" huh ? \" through most of the film . the details of the plot are slowly given out as the movie progresses and it 's almost enough to make it interesting except there was n't enough explanation as it moved on and so i was almost lost until the last 2 / 3 of it . \n",
       "\n",
       " if you 're a die - hard thriller fan , it 's worth seeing at least once . if there 's nothing better at the theater and you really want to watch a movie , eh , i guess it 's worth a matinée ticket . if you thought the trailer made it look like an interesting movie and you ca n't wait ... wait ., Text xxbos this is a very funny movie , easy to watch , that entertains you almost all the time . the work of the director is recognizable and the type of humor is his trademark . the movie is a typical police partners history like lethal weapon , but the jokes and comedy are of argentinian sort . the twist is that one of them is a psychologist played by peretti and has to go with detective diaz ( played by luque ) on his assignments while he also assist him ( diaz is troubled because his wife cheated on him ) . some of the dialogs are hilarious worldwide : understandable and laughable anywhere . is very good overall , it would deserved an 8 , but i rated 7 because it gets a little down at the end . on a personal remark i must add that is a \" bravo \" for argentinian filmmakers , considering the little good is coming lately .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos i thought it will be a ok movie after seeing the commercials about it . it was funny at some parts and some very nasty . the only person i felt sorry for is horatio sans who got a hot wife who is cheating on him with other women . but he never got a chance to have a threesome with until the and that was good but they should have made more bigger thru out the film ., Text xxbos i enjoyed carax 's \" les amants du pont neuf \" and was therefore expecting this film to be of a similar standard . well , the first 10 minutes were ok , but then it disintegrates into a rather pretentious journey of a young man looking for the essence of life . a sad disappointment ., Text xxbos what 's the matter with you people ? john dahl ? from \" rounders \" and \" unforgettable \" ? xxup too quirky ? knocking emma thompson and alan rickman for having fun playing against type ? and somebody liked the gingerbread man ? \n",
       "\n",
       " i rented this not knowing anything about it and found it about as nifty a video find as you can get . never insulting , well thought out , funny , scary . i disagree with the naysayers , clearly . i thought the story itself was unremarkable but the great cast , which most likely means the director was paying attention , lifted it to super cool status . good sound design also ( much more appreciated in surround , but i 'm not bragging ) . and yes , i 'm a girl , so maybe it has a slight female slant ( the guys in the gang are pretty worthwhile ) . all in all , a 9 and a hearty xxup recommend ., Text xxbos johnnie ( bert wheeler ) is a would - be songwriter ; newton ( robert woolsey ) is a would - be inventor . both work at a cigar stand in the lobby of an office building . johnnie wants to sell a song to winfield lake , a song publisher who also owns the building . lake 's secretary , mary ( betty grable ) , is johnnie 's sweetheart . when lake turns up dead , circumstances conspire to make mary and newton think that johnnie is the killer . they conspire again to implicate mary , who goes to jail . but who really shot lake ? who is the black widow , the blackmailer who had threatened him ? the other characters in this wacky murder mystery are : lake 's suspicious wife , a self - satisfied private detective , a seemingly slow - witted janitor ( willie best ) , lake 's auditor , a songwriter who thinks lake is stealing from him and another who thinks everyone is stealing from him . it 's up to newton and his truth machine to reveal the real killer . \n",
       "\n",
       " the baby - voiced wheeler and the cigar - chomping woolsey strike me as an arbitrary pairing , but they made several movies together in the 30s and some of them were funny . \n",
       "\n",
       " not this one . george stevens , who went on to have a distinguished career , directed this dismal comedy with a tedious murder mystery plot . but two scenes are good , and both feature wheeler and betty grable singing the excellent \" music in my heart , \" written by dorothy fields and jimmy mchugh . the first time , they sing it walking up a staircase ( after which they dance back down ) . later , wheeler and woolsey are on stilts so that they can see and talk to mary , who is in a jail cell on a high floor . wheeler and grable sing to each other through the bars . \n",
       "\n",
       " \" the nitwits \" has a few laughs , but the level of comedy is best illustrated by woolsey 's line : \" sonny , you 've got the brain of a six - year - old boy . and i 'll bet even he was glad to get rid of it . \" it 's watered - down xxunk did n't use the superfluous \" even \" when he said it ., Text xxbos this film has the guts to suggest that it might be best to simply accept your life as it is , and keep smiling anyway . as one who is more excited by the idea of taking charge of one 's life and moving forward , i felt slapped in the face , but that 's okay : i do n't have to agree with a movie to love it and respect it . great acting by streep and hurt , and everyone else really , and some wonderfully quirky scenes . a serious film . and take a hanky .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60004, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "      (3): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f40b2b92080>, metrics=[<function accuracy at 0x7f40b41b2730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/farzin/rnn_python_code/wiki103_from_download/clas'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos another trashy grade z quickie from the prolific albert pyun . tim xxunk 13 inch clint eastwood - like cop from outer space chases an ugly flying head ( ! ) to earth and gets involved in a gang war in south bronx ! mercifully short , but xxunk dull , with the cheesiest effects since attack of the 50 ft woman . they should have fired the continuity guy , too : note how xxunk sunglasses disappears and reappears in every second shot . laughably bad , but that´s why we watch these movies , xxunk it ? sequel ´ dollman vs. demonic toys ´ is reportedly even worse , if that´s possible . \n",
       "\n",
       " 0 ( of xxrep 4 * ) \n",
       "\n",
       ", Text xxbos this show stinks . for parents , they usually want their kids to watch something good for them . it is usually educational , funny , and bright . \n",
       "\n",
       " is it educational ? no . the doodlebops sing and that 's it . they usually sing about themselves , they do n't try teaching anything . \n",
       "\n",
       " is it funny ? no . the doodlebops instead say something which is not intended as a joke , and laugh at it . \n",
       "\n",
       " is it bright ? it 's so bright , it 's painful . as far as color , s everything is extremely bright , so that 's good . but xxup nothing is ever wrong in the world of the xxunk 's . therefore , they are always happy . a kid in trouble will become depressed because they have never been exposed to being sad . \n",
       "\n",
       " the show is also extremely cheesy . every syllable is said to the highest level of exaggeration and very corny . it 's overkill . \n",
       "\n",
       " for kids , it 's entertaining , but past the age of 2 you wo n't want your kids to see it . they 'll never know how to grow up ., Text xxbos just two comments xxrep 4 . xxup seven years apart ? hardly evidence of the film 's relentless pulling - power ! as has been mentioned , the low - budget telemovie status of 13 xxup gantry xxup row is a mitigating factor in its limited appeal . having said that however the thing is not without merit - either as entertainment or as a fright outing per se . \n",
       "\n",
       " true , the plot at its most basic is a re - working of xxup the xxup amityville xxup horror - only without much horror . more a case of intrigue ! gibney might have made a more worthwhile impression if she had played xxunk xxunk a couple of seemingly unconnected murders with the \" house \" as the main suspect . the script is better than average and the production overall of a high standard . it just fails to engage the viewer particularly at key moments . \n",
       "\n",
       " having picked the xxup dvd up for a mere $ xxunk last week at my regular video store , i can not begrudge the expenditure . $ xxunk would be an acceptable price for the film . just do n't expect fireworks !, Text xxbos xxup some xxup not - so- xxup xxunk xxup spoilers xxup ahead \n",
       "\n",
       " why do people , when they are disoriented or sick or scared at a club , cut through the middle of the crowded dance floor on their way to the bathroom ? \n",
       "\n",
       " who in their right mind would hide under a bed when someone breaks into their room ? \n",
       "\n",
       " how often do you knock on a stranger 's door and when they do n't xxup immediately answer , you open the door , walk in , shout a few hello 's and then start going through their stuff ? \n",
       "\n",
       " if you were being pursued by someone you just discovered was a murderer , what would you do ? quietly sneak off and hide under a wooden platform or among metal implements ? run , quietly of course , to a ratty old barn or other decrepit structure ? \n",
       "\n",
       " i could be talking about almost any thriller that 's come out in the last few years , but since this is the \" the return \" page , obviously i 'm talking about \" the return . \" i saw it free because i work at a movie theater and make a point of screening all the \" scary \" movies . i thought this one was tolerable ... aside from the well - worn clichés . sarah michelle gellar is really drab and looks kind of \" huh ? \" through most of the film . the details of the plot are slowly given out as the movie progresses and it 's almost enough to make it interesting except there was n't enough explanation as it moved on and so i was almost lost until the last 2 / 3 of it . \n",
       "\n",
       " if you 're a die - hard thriller fan , it 's worth seeing at least once . if there 's nothing better at the theater and you really want to watch a movie , eh , i guess it 's worth a matinée ticket . if you thought the trailer made it look like an interesting movie and you ca n't wait ... wait ., Text xxbos this is a very funny movie , easy to watch , that entertains you almost all the time . the work of the director is recognizable and the type of humor is his trademark . the movie is a typical police partners history like lethal weapon , but the jokes and comedy are of argentinian sort . the twist is that one of them is a psychologist played by peretti and has to go with detective diaz ( played by luque ) on his assignments while he also assist him ( diaz is troubled because his wife cheated on him ) . some of the dialogs are hilarious worldwide : understandable and laughable anywhere . is very good overall , it would deserved an 8 , but i rated 7 because it gets a little down at the end . on a personal remark i must add that is a \" bravo \" for argentinian filmmakers , considering the little good is coming lately .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos i thought it will be a ok movie after seeing the commercials about it . it was funny at some parts and some very nasty . the only person i felt sorry for is horatio sans who got a hot wife who is cheating on him with other women . but he never got a chance to have a threesome with until the and that was good but they should have made more bigger thru out the film ., Text xxbos i enjoyed carax 's \" les amants du pont neuf \" and was therefore expecting this film to be of a similar standard . well , the first 10 minutes were ok , but then it disintegrates into a rather pretentious journey of a young man looking for the essence of life . a sad disappointment ., Text xxbos what 's the matter with you people ? john dahl ? from \" rounders \" and \" unforgettable \" ? xxup too quirky ? knocking emma thompson and alan rickman for having fun playing against type ? and somebody liked the gingerbread man ? \n",
       "\n",
       " i rented this not knowing anything about it and found it about as nifty a video find as you can get . never insulting , well thought out , funny , scary . i disagree with the naysayers , clearly . i thought the story itself was unremarkable but the great cast , which most likely means the director was paying attention , lifted it to super cool status . good sound design also ( much more appreciated in surround , but i 'm not bragging ) . and yes , i 'm a girl , so maybe it has a slight female slant ( the guys in the gang are pretty worthwhile ) . all in all , a 9 and a hearty xxup recommend ., Text xxbos johnnie ( bert wheeler ) is a would - be songwriter ; newton ( robert woolsey ) is a would - be inventor . both work at a cigar stand in the lobby of an office building . johnnie wants to sell a song to winfield lake , a song publisher who also owns the building . lake 's secretary , mary ( betty grable ) , is johnnie 's sweetheart . when lake turns up dead , circumstances conspire to make mary and newton think that johnnie is the killer . they conspire again to implicate mary , who goes to jail . but who really shot lake ? who is the black widow , the blackmailer who had threatened him ? the other characters in this wacky murder mystery are : lake 's suspicious wife , a self - satisfied private detective , a seemingly slow - witted janitor ( willie best ) , lake 's auditor , a songwriter who thinks lake is stealing from him and another who thinks everyone is stealing from him . it 's up to newton and his truth machine to reveal the real killer . \n",
       "\n",
       " the baby - voiced wheeler and the cigar - chomping woolsey strike me as an arbitrary pairing , but they made several movies together in the 30s and some of them were funny . \n",
       "\n",
       " not this one . george stevens , who went on to have a distinguished career , directed this dismal comedy with a tedious murder mystery plot . but two scenes are good , and both feature wheeler and betty grable singing the excellent \" music in my heart , \" written by dorothy fields and jimmy mchugh . the first time , they sing it walking up a staircase ( after which they dance back down ) . later , wheeler and woolsey are on stilts so that they can see and talk to mary , who is in a jail cell on a high floor . wheeler and grable sing to each other through the bars . \n",
       "\n",
       " \" the nitwits \" has a few laughs , but the level of comedy is best illustrated by woolsey 's line : \" sonny , you 've got the brain of a six - year - old boy . and i 'll bet even he was glad to get rid of it . \" it 's watered - down xxunk did n't use the superfluous \" even \" when he said it ., Text xxbos this film has the guts to suggest that it might be best to simply accept your life as it is , and keep smiling anyway . as one who is more excited by the idea of taking charge of one 's life and moving forward , i felt slapped in the face , but that 's okay : i do n't have to agree with a movie to love it and respect it . great acting by streep and hurt , and everyone else really , and some wonderfully quirky scenes . a serious film . and take a hanky .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60004, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "      (3): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f40b2b92080>, metrics=[<function accuracy at 0x7f40b41b2730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/farzin/rnn_python_code/wiki103_from_download/clas'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])\n",
       "bptt: 140\n",
       "alpha: 2.0\n",
       "beta: 1.0\n",
       "adjust: False], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data_clas.batch_size = 16\n",
    "learn_cls = text_classifier_learner(imdb_data_clas,bptt,emb_sz,nh,nl,drop_mult=0.5,qrnn=True)\n",
    "learn_cls.load_encoder('fine_tuned_enc60kb')\n",
    "learn_cls.freeze()\n",
    "learn_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try FocalLoss to refine the fit?  Get those marginal cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_cls.loss_func.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, num_classes,gamma=0, weight=None,size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.size_average = size_average\n",
    "        if weight is None:\n",
    "            self.weight = torch.ones(num_classes,1)#tensor with weights of 1 / num classes\n",
    "        else:\n",
    "            self.weight = weight            #tensor with weights from vector\n",
    "\n",
    "    def forward(self, pred, target):        \n",
    "        logpt = F.log_softmax(pred,dim=1)                      # take log softmax\n",
    "        tgt_logpt = logpt.gather(1,target.view(-1,1))    # look at selected cases\n",
    "        pt = torch.exp(tgt_logpt.view(-1))               # unroll and convert to Prob\n",
    "        loss = -((1-pt)**self.gamma) * tgt_logpt.view(-1)\n",
    "            \n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_loss = FocalLoss(num_classes=2,gamma=8., weight=None,size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FocalLoss()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_cls.loss_func.func = f_loss\n",
    "learn_cls.loss_func.func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### proceed with LR find and learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_find(learn_cls)\n",
    "learn_cls.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:21 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.001525</th>\n",
       "    <th>0.001160</th>\n",
       "    <th>0.904160</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.fit_one_cycle(1, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:48 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.001642</th>\n",
       "    <th>0.001391</th>\n",
       "    <th>0.882240</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.001462</th>\n",
       "    <th>0.001112</th>\n",
       "    <th>0.916280</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.fit_one_cycle(2, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:37 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.001766</th>\n",
       "    <th>0.006221</th>\n",
       "    <th>0.876840</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.001598</th>\n",
       "    <th>0.001066</th>\n",
       "    <th>0.913800</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.001562</th>\n",
       "    <th>0.001034</th>\n",
       "    <th>0.915000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.001492</th>\n",
       "    <th>0.001080</th>\n",
       "    <th>0.917400</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.fit_one_cycle(4, 2e-2, moms=(0.8,0.7),pct_start=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:59 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.001524</th>\n",
       "    <th>0.001303</th>\n",
       "    <th>0.917280</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.001371</th>\n",
       "    <th>0.000977</th>\n",
       "    <th>0.923880</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.001481</th>\n",
       "    <th>0.001026</th>\n",
       "    <th>0.930000</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.001248</th>\n",
       "    <th>0.000950</th>\n",
       "    <th>0.932240</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.freeze_to(-2)\n",
    "learn_cls.fit_one_cycle(4, slice(2e-2/2.6,1e-2), moms=(0.8,0.7), pct_start=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.save('second_FL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos another trashy grade z quickie from the prolific albert pyun . tim xxunk 13 inch clint eastwood - like cop from outer space chases an ugly flying head ( ! ) to earth and gets involved in a gang war in south bronx ! mercifully short , but xxunk dull , with the cheesiest effects since attack of the 50 ft woman . they should have fired the continuity guy , too : note how xxunk sunglasses disappears and reappears in every second shot . laughably bad , but that´s why we watch these movies , xxunk it ? sequel ´ dollman vs. demonic toys ´ is reportedly even worse , if that´s possible . \n",
       "\n",
       " 0 ( of xxrep 4 * ) \n",
       "\n",
       ", Text xxbos this show stinks . for parents , they usually want their kids to watch something good for them . it is usually educational , funny , and bright . \n",
       "\n",
       " is it educational ? no . the doodlebops sing and that 's it . they usually sing about themselves , they do n't try teaching anything . \n",
       "\n",
       " is it funny ? no . the doodlebops instead say something which is not intended as a joke , and laugh at it . \n",
       "\n",
       " is it bright ? it 's so bright , it 's painful . as far as color , s everything is extremely bright , so that 's good . but xxup nothing is ever wrong in the world of the xxunk 's . therefore , they are always happy . a kid in trouble will become depressed because they have never been exposed to being sad . \n",
       "\n",
       " the show is also extremely cheesy . every syllable is said to the highest level of exaggeration and very corny . it 's overkill . \n",
       "\n",
       " for kids , it 's entertaining , but past the age of 2 you wo n't want your kids to see it . they 'll never know how to grow up ., Text xxbos just two comments xxrep 4 . xxup seven years apart ? hardly evidence of the film 's relentless pulling - power ! as has been mentioned , the low - budget telemovie status of 13 xxup gantry xxup row is a mitigating factor in its limited appeal . having said that however the thing is not without merit - either as entertainment or as a fright outing per se . \n",
       "\n",
       " true , the plot at its most basic is a re - working of xxup the xxup amityville xxup horror - only without much horror . more a case of intrigue ! gibney might have made a more worthwhile impression if she had played xxunk xxunk a couple of seemingly unconnected murders with the \" house \" as the main suspect . the script is better than average and the production overall of a high standard . it just fails to engage the viewer particularly at key moments . \n",
       "\n",
       " having picked the xxup dvd up for a mere $ xxunk last week at my regular video store , i can not begrudge the expenditure . $ xxunk would be an acceptable price for the film . just do n't expect fireworks !, Text xxbos xxup some xxup not - so- xxup xxunk xxup spoilers xxup ahead \n",
       "\n",
       " why do people , when they are disoriented or sick or scared at a club , cut through the middle of the crowded dance floor on their way to the bathroom ? \n",
       "\n",
       " who in their right mind would hide under a bed when someone breaks into their room ? \n",
       "\n",
       " how often do you knock on a stranger 's door and when they do n't xxup immediately answer , you open the door , walk in , shout a few hello 's and then start going through their stuff ? \n",
       "\n",
       " if you were being pursued by someone you just discovered was a murderer , what would you do ? quietly sneak off and hide under a wooden platform or among metal implements ? run , quietly of course , to a ratty old barn or other decrepit structure ? \n",
       "\n",
       " i could be talking about almost any thriller that 's come out in the last few years , but since this is the \" the return \" page , obviously i 'm talking about \" the return . \" i saw it free because i work at a movie theater and make a point of screening all the \" scary \" movies . i thought this one was tolerable ... aside from the well - worn clichés . sarah michelle gellar is really drab and looks kind of \" huh ? \" through most of the film . the details of the plot are slowly given out as the movie progresses and it 's almost enough to make it interesting except there was n't enough explanation as it moved on and so i was almost lost until the last 2 / 3 of it . \n",
       "\n",
       " if you 're a die - hard thriller fan , it 's worth seeing at least once . if there 's nothing better at the theater and you really want to watch a movie , eh , i guess it 's worth a matinée ticket . if you thought the trailer made it look like an interesting movie and you ca n't wait ... wait ., Text xxbos this is a very funny movie , easy to watch , that entertains you almost all the time . the work of the director is recognizable and the type of humor is his trademark . the movie is a typical police partners history like lethal weapon , but the jokes and comedy are of argentinian sort . the twist is that one of them is a psychologist played by peretti and has to go with detective diaz ( played by luque ) on his assignments while he also assist him ( diaz is troubled because his wife cheated on him ) . some of the dialogs are hilarious worldwide : understandable and laughable anywhere . is very good overall , it would deserved an 8 , but i rated 7 because it gets a little down at the end . on a personal remark i must add that is a \" bravo \" for argentinian filmmakers , considering the little good is coming lately .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos i thought it will be a ok movie after seeing the commercials about it . it was funny at some parts and some very nasty . the only person i felt sorry for is horatio sans who got a hot wife who is cheating on him with other women . but he never got a chance to have a threesome with until the and that was good but they should have made more bigger thru out the film ., Text xxbos i enjoyed carax 's \" les amants du pont neuf \" and was therefore expecting this film to be of a similar standard . well , the first 10 minutes were ok , but then it disintegrates into a rather pretentious journey of a young man looking for the essence of life . a sad disappointment ., Text xxbos what 's the matter with you people ? john dahl ? from \" rounders \" and \" unforgettable \" ? xxup too quirky ? knocking emma thompson and alan rickman for having fun playing against type ? and somebody liked the gingerbread man ? \n",
       "\n",
       " i rented this not knowing anything about it and found it about as nifty a video find as you can get . never insulting , well thought out , funny , scary . i disagree with the naysayers , clearly . i thought the story itself was unremarkable but the great cast , which most likely means the director was paying attention , lifted it to super cool status . good sound design also ( much more appreciated in surround , but i 'm not bragging ) . and yes , i 'm a girl , so maybe it has a slight female slant ( the guys in the gang are pretty worthwhile ) . all in all , a 9 and a hearty xxup recommend ., Text xxbos johnnie ( bert wheeler ) is a would - be songwriter ; newton ( robert woolsey ) is a would - be inventor . both work at a cigar stand in the lobby of an office building . johnnie wants to sell a song to winfield lake , a song publisher who also owns the building . lake 's secretary , mary ( betty grable ) , is johnnie 's sweetheart . when lake turns up dead , circumstances conspire to make mary and newton think that johnnie is the killer . they conspire again to implicate mary , who goes to jail . but who really shot lake ? who is the black widow , the blackmailer who had threatened him ? the other characters in this wacky murder mystery are : lake 's suspicious wife , a self - satisfied private detective , a seemingly slow - witted janitor ( willie best ) , lake 's auditor , a songwriter who thinks lake is stealing from him and another who thinks everyone is stealing from him . it 's up to newton and his truth machine to reveal the real killer . \n",
       "\n",
       " the baby - voiced wheeler and the cigar - chomping woolsey strike me as an arbitrary pairing , but they made several movies together in the 30s and some of them were funny . \n",
       "\n",
       " not this one . george stevens , who went on to have a distinguished career , directed this dismal comedy with a tedious murder mystery plot . but two scenes are good , and both feature wheeler and betty grable singing the excellent \" music in my heart , \" written by dorothy fields and jimmy mchugh . the first time , they sing it walking up a staircase ( after which they dance back down ) . later , wheeler and woolsey are on stilts so that they can see and talk to mary , who is in a jail cell on a high floor . wheeler and grable sing to each other through the bars . \n",
       "\n",
       " \" the nitwits \" has a few laughs , but the level of comedy is best illustrated by woolsey 's line : \" sonny , you 've got the brain of a six - year - old boy . and i 'll bet even he was glad to get rid of it . \" it 's watered - down xxunk did n't use the superfluous \" even \" when he said it ., Text xxbos this film has the guts to suggest that it might be best to simply accept your life as it is , and keep smiling anyway . as one who is more excited by the idea of taking charge of one 's life and moving forward , i felt slapped in the face , but that 's okay : i do n't have to agree with a movie to love it and respect it . great acting by streep and hurt , and everyone else really , and some wonderfully quirky scenes . a serious film . and take a hanky .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60004, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "      (3): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f40b2b92080>, metrics=[<function accuracy at 0x7f40b41b2730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/farzin/rnn_python_code/wiki103_from_download/clas'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos another trashy grade z quickie from the prolific albert pyun . tim xxunk 13 inch clint eastwood - like cop from outer space chases an ugly flying head ( ! ) to earth and gets involved in a gang war in south bronx ! mercifully short , but xxunk dull , with the cheesiest effects since attack of the 50 ft woman . they should have fired the continuity guy , too : note how xxunk sunglasses disappears and reappears in every second shot . laughably bad , but that´s why we watch these movies , xxunk it ? sequel ´ dollman vs. demonic toys ´ is reportedly even worse , if that´s possible . \n",
       "\n",
       " 0 ( of xxrep 4 * ) \n",
       "\n",
       ", Text xxbos this show stinks . for parents , they usually want their kids to watch something good for them . it is usually educational , funny , and bright . \n",
       "\n",
       " is it educational ? no . the doodlebops sing and that 's it . they usually sing about themselves , they do n't try teaching anything . \n",
       "\n",
       " is it funny ? no . the doodlebops instead say something which is not intended as a joke , and laugh at it . \n",
       "\n",
       " is it bright ? it 's so bright , it 's painful . as far as color , s everything is extremely bright , so that 's good . but xxup nothing is ever wrong in the world of the xxunk 's . therefore , they are always happy . a kid in trouble will become depressed because they have never been exposed to being sad . \n",
       "\n",
       " the show is also extremely cheesy . every syllable is said to the highest level of exaggeration and very corny . it 's overkill . \n",
       "\n",
       " for kids , it 's entertaining , but past the age of 2 you wo n't want your kids to see it . they 'll never know how to grow up ., Text xxbos just two comments xxrep 4 . xxup seven years apart ? hardly evidence of the film 's relentless pulling - power ! as has been mentioned , the low - budget telemovie status of 13 xxup gantry xxup row is a mitigating factor in its limited appeal . having said that however the thing is not without merit - either as entertainment or as a fright outing per se . \n",
       "\n",
       " true , the plot at its most basic is a re - working of xxup the xxup amityville xxup horror - only without much horror . more a case of intrigue ! gibney might have made a more worthwhile impression if she had played xxunk xxunk a couple of seemingly unconnected murders with the \" house \" as the main suspect . the script is better than average and the production overall of a high standard . it just fails to engage the viewer particularly at key moments . \n",
       "\n",
       " having picked the xxup dvd up for a mere $ xxunk last week at my regular video store , i can not begrudge the expenditure . $ xxunk would be an acceptable price for the film . just do n't expect fireworks !, Text xxbos xxup some xxup not - so- xxup xxunk xxup spoilers xxup ahead \n",
       "\n",
       " why do people , when they are disoriented or sick or scared at a club , cut through the middle of the crowded dance floor on their way to the bathroom ? \n",
       "\n",
       " who in their right mind would hide under a bed when someone breaks into their room ? \n",
       "\n",
       " how often do you knock on a stranger 's door and when they do n't xxup immediately answer , you open the door , walk in , shout a few hello 's and then start going through their stuff ? \n",
       "\n",
       " if you were being pursued by someone you just discovered was a murderer , what would you do ? quietly sneak off and hide under a wooden platform or among metal implements ? run , quietly of course , to a ratty old barn or other decrepit structure ? \n",
       "\n",
       " i could be talking about almost any thriller that 's come out in the last few years , but since this is the \" the return \" page , obviously i 'm talking about \" the return . \" i saw it free because i work at a movie theater and make a point of screening all the \" scary \" movies . i thought this one was tolerable ... aside from the well - worn clichés . sarah michelle gellar is really drab and looks kind of \" huh ? \" through most of the film . the details of the plot are slowly given out as the movie progresses and it 's almost enough to make it interesting except there was n't enough explanation as it moved on and so i was almost lost until the last 2 / 3 of it . \n",
       "\n",
       " if you 're a die - hard thriller fan , it 's worth seeing at least once . if there 's nothing better at the theater and you really want to watch a movie , eh , i guess it 's worth a matinée ticket . if you thought the trailer made it look like an interesting movie and you ca n't wait ... wait ., Text xxbos this is a very funny movie , easy to watch , that entertains you almost all the time . the work of the director is recognizable and the type of humor is his trademark . the movie is a typical police partners history like lethal weapon , but the jokes and comedy are of argentinian sort . the twist is that one of them is a psychologist played by peretti and has to go with detective diaz ( played by luque ) on his assignments while he also assist him ( diaz is troubled because his wife cheated on him ) . some of the dialogs are hilarious worldwide : understandable and laughable anywhere . is very good overall , it would deserved an 8 , but i rated 7 because it gets a little down at the end . on a personal remark i must add that is a \" bravo \" for argentinian filmmakers , considering the little good is coming lately .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos i thought it will be a ok movie after seeing the commercials about it . it was funny at some parts and some very nasty . the only person i felt sorry for is horatio sans who got a hot wife who is cheating on him with other women . but he never got a chance to have a threesome with until the and that was good but they should have made more bigger thru out the film ., Text xxbos i enjoyed carax 's \" les amants du pont neuf \" and was therefore expecting this film to be of a similar standard . well , the first 10 minutes were ok , but then it disintegrates into a rather pretentious journey of a young man looking for the essence of life . a sad disappointment ., Text xxbos what 's the matter with you people ? john dahl ? from \" rounders \" and \" unforgettable \" ? xxup too quirky ? knocking emma thompson and alan rickman for having fun playing against type ? and somebody liked the gingerbread man ? \n",
       "\n",
       " i rented this not knowing anything about it and found it about as nifty a video find as you can get . never insulting , well thought out , funny , scary . i disagree with the naysayers , clearly . i thought the story itself was unremarkable but the great cast , which most likely means the director was paying attention , lifted it to super cool status . good sound design also ( much more appreciated in surround , but i 'm not bragging ) . and yes , i 'm a girl , so maybe it has a slight female slant ( the guys in the gang are pretty worthwhile ) . all in all , a 9 and a hearty xxup recommend ., Text xxbos johnnie ( bert wheeler ) is a would - be songwriter ; newton ( robert woolsey ) is a would - be inventor . both work at a cigar stand in the lobby of an office building . johnnie wants to sell a song to winfield lake , a song publisher who also owns the building . lake 's secretary , mary ( betty grable ) , is johnnie 's sweetheart . when lake turns up dead , circumstances conspire to make mary and newton think that johnnie is the killer . they conspire again to implicate mary , who goes to jail . but who really shot lake ? who is the black widow , the blackmailer who had threatened him ? the other characters in this wacky murder mystery are : lake 's suspicious wife , a self - satisfied private detective , a seemingly slow - witted janitor ( willie best ) , lake 's auditor , a songwriter who thinks lake is stealing from him and another who thinks everyone is stealing from him . it 's up to newton and his truth machine to reveal the real killer . \n",
       "\n",
       " the baby - voiced wheeler and the cigar - chomping woolsey strike me as an arbitrary pairing , but they made several movies together in the 30s and some of them were funny . \n",
       "\n",
       " not this one . george stevens , who went on to have a distinguished career , directed this dismal comedy with a tedious murder mystery plot . but two scenes are good , and both feature wheeler and betty grable singing the excellent \" music in my heart , \" written by dorothy fields and jimmy mchugh . the first time , they sing it walking up a staircase ( after which they dance back down ) . later , wheeler and woolsey are on stilts so that they can see and talk to mary , who is in a jail cell on a high floor . wheeler and grable sing to each other through the bars . \n",
       "\n",
       " \" the nitwits \" has a few laughs , but the level of comedy is best illustrated by woolsey 's line : \" sonny , you 've got the brain of a six - year - old boy . and i 'll bet even he was glad to get rid of it . \" it 's watered - down xxunk did n't use the superfluous \" even \" when he said it ., Text xxbos this film has the guts to suggest that it might be best to simply accept your life as it is , and keep smiling anyway . as one who is more excited by the idea of taking charge of one 's life and moving forward , i felt slapped in the face , but that 's okay : i do n't have to agree with a movie to love it and respect it . great acting by streep and hurt , and everyone else really , and some wonderfully quirky scenes . a serious film . and take a hanky .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60004, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "      (3): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f40b2b92080>, metrics=[<function accuracy at 0x7f40b41b2730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/farzin/rnn_python_code/wiki103_from_download/clas'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])\n",
       "bptt: 140\n",
       "alpha: 2.0\n",
       "beta: 1.0\n",
       "adjust: False], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_cls.load('second_FL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 07:05 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.001378</th>\n",
       "    <th>0.000970</th>\n",
       "    <th>0.931120</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.001321</th>\n",
       "    <th>0.001231</th>\n",
       "    <th>0.932960</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.001240</th>\n",
       "    <th>0.001065</th>\n",
       "    <th>0.934360</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.001089</th>\n",
       "    <th>0.001199</th>\n",
       "    <th>0.939760</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.freeze_to(-3)\n",
    "learn_cls.fit_one_cycle(4, slice(2e-2/(2.6**2),0.5e-2), moms=(0.8,0.7), pct_start=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.save('third_FL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos another trashy grade z quickie from the prolific albert pyun . tim xxunk 13 inch clint eastwood - like cop from outer space chases an ugly flying head ( ! ) to earth and gets involved in a gang war in south bronx ! mercifully short , but xxunk dull , with the cheesiest effects since attack of the 50 ft woman . they should have fired the continuity guy , too : note how xxunk sunglasses disappears and reappears in every second shot . laughably bad , but that´s why we watch these movies , xxunk it ? sequel ´ dollman vs. demonic toys ´ is reportedly even worse , if that´s possible . \n",
       "\n",
       " 0 ( of xxrep 4 * ) \n",
       "\n",
       ", Text xxbos this show stinks . for parents , they usually want their kids to watch something good for them . it is usually educational , funny , and bright . \n",
       "\n",
       " is it educational ? no . the doodlebops sing and that 's it . they usually sing about themselves , they do n't try teaching anything . \n",
       "\n",
       " is it funny ? no . the doodlebops instead say something which is not intended as a joke , and laugh at it . \n",
       "\n",
       " is it bright ? it 's so bright , it 's painful . as far as color , s everything is extremely bright , so that 's good . but xxup nothing is ever wrong in the world of the xxunk 's . therefore , they are always happy . a kid in trouble will become depressed because they have never been exposed to being sad . \n",
       "\n",
       " the show is also extremely cheesy . every syllable is said to the highest level of exaggeration and very corny . it 's overkill . \n",
       "\n",
       " for kids , it 's entertaining , but past the age of 2 you wo n't want your kids to see it . they 'll never know how to grow up ., Text xxbos just two comments xxrep 4 . xxup seven years apart ? hardly evidence of the film 's relentless pulling - power ! as has been mentioned , the low - budget telemovie status of 13 xxup gantry xxup row is a mitigating factor in its limited appeal . having said that however the thing is not without merit - either as entertainment or as a fright outing per se . \n",
       "\n",
       " true , the plot at its most basic is a re - working of xxup the xxup amityville xxup horror - only without much horror . more a case of intrigue ! gibney might have made a more worthwhile impression if she had played xxunk xxunk a couple of seemingly unconnected murders with the \" house \" as the main suspect . the script is better than average and the production overall of a high standard . it just fails to engage the viewer particularly at key moments . \n",
       "\n",
       " having picked the xxup dvd up for a mere $ xxunk last week at my regular video store , i can not begrudge the expenditure . $ xxunk would be an acceptable price for the film . just do n't expect fireworks !, Text xxbos xxup some xxup not - so- xxup xxunk xxup spoilers xxup ahead \n",
       "\n",
       " why do people , when they are disoriented or sick or scared at a club , cut through the middle of the crowded dance floor on their way to the bathroom ? \n",
       "\n",
       " who in their right mind would hide under a bed when someone breaks into their room ? \n",
       "\n",
       " how often do you knock on a stranger 's door and when they do n't xxup immediately answer , you open the door , walk in , shout a few hello 's and then start going through their stuff ? \n",
       "\n",
       " if you were being pursued by someone you just discovered was a murderer , what would you do ? quietly sneak off and hide under a wooden platform or among metal implements ? run , quietly of course , to a ratty old barn or other decrepit structure ? \n",
       "\n",
       " i could be talking about almost any thriller that 's come out in the last few years , but since this is the \" the return \" page , obviously i 'm talking about \" the return . \" i saw it free because i work at a movie theater and make a point of screening all the \" scary \" movies . i thought this one was tolerable ... aside from the well - worn clichés . sarah michelle gellar is really drab and looks kind of \" huh ? \" through most of the film . the details of the plot are slowly given out as the movie progresses and it 's almost enough to make it interesting except there was n't enough explanation as it moved on and so i was almost lost until the last 2 / 3 of it . \n",
       "\n",
       " if you 're a die - hard thriller fan , it 's worth seeing at least once . if there 's nothing better at the theater and you really want to watch a movie , eh , i guess it 's worth a matinée ticket . if you thought the trailer made it look like an interesting movie and you ca n't wait ... wait ., Text xxbos this is a very funny movie , easy to watch , that entertains you almost all the time . the work of the director is recognizable and the type of humor is his trademark . the movie is a typical police partners history like lethal weapon , but the jokes and comedy are of argentinian sort . the twist is that one of them is a psychologist played by peretti and has to go with detective diaz ( played by luque ) on his assignments while he also assist him ( diaz is troubled because his wife cheated on him ) . some of the dialogs are hilarious worldwide : understandable and laughable anywhere . is very good overall , it would deserved an 8 , but i rated 7 because it gets a little down at the end . on a personal remark i must add that is a \" bravo \" for argentinian filmmakers , considering the little good is coming lately .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos i thought it will be a ok movie after seeing the commercials about it . it was funny at some parts and some very nasty . the only person i felt sorry for is horatio sans who got a hot wife who is cheating on him with other women . but he never got a chance to have a threesome with until the and that was good but they should have made more bigger thru out the film ., Text xxbos i enjoyed carax 's \" les amants du pont neuf \" and was therefore expecting this film to be of a similar standard . well , the first 10 minutes were ok , but then it disintegrates into a rather pretentious journey of a young man looking for the essence of life . a sad disappointment ., Text xxbos what 's the matter with you people ? john dahl ? from \" rounders \" and \" unforgettable \" ? xxup too quirky ? knocking emma thompson and alan rickman for having fun playing against type ? and somebody liked the gingerbread man ? \n",
       "\n",
       " i rented this not knowing anything about it and found it about as nifty a video find as you can get . never insulting , well thought out , funny , scary . i disagree with the naysayers , clearly . i thought the story itself was unremarkable but the great cast , which most likely means the director was paying attention , lifted it to super cool status . good sound design also ( much more appreciated in surround , but i 'm not bragging ) . and yes , i 'm a girl , so maybe it has a slight female slant ( the guys in the gang are pretty worthwhile ) . all in all , a 9 and a hearty xxup recommend ., Text xxbos johnnie ( bert wheeler ) is a would - be songwriter ; newton ( robert woolsey ) is a would - be inventor . both work at a cigar stand in the lobby of an office building . johnnie wants to sell a song to winfield lake , a song publisher who also owns the building . lake 's secretary , mary ( betty grable ) , is johnnie 's sweetheart . when lake turns up dead , circumstances conspire to make mary and newton think that johnnie is the killer . they conspire again to implicate mary , who goes to jail . but who really shot lake ? who is the black widow , the blackmailer who had threatened him ? the other characters in this wacky murder mystery are : lake 's suspicious wife , a self - satisfied private detective , a seemingly slow - witted janitor ( willie best ) , lake 's auditor , a songwriter who thinks lake is stealing from him and another who thinks everyone is stealing from him . it 's up to newton and his truth machine to reveal the real killer . \n",
       "\n",
       " the baby - voiced wheeler and the cigar - chomping woolsey strike me as an arbitrary pairing , but they made several movies together in the 30s and some of them were funny . \n",
       "\n",
       " not this one . george stevens , who went on to have a distinguished career , directed this dismal comedy with a tedious murder mystery plot . but two scenes are good , and both feature wheeler and betty grable singing the excellent \" music in my heart , \" written by dorothy fields and jimmy mchugh . the first time , they sing it walking up a staircase ( after which they dance back down ) . later , wheeler and woolsey are on stilts so that they can see and talk to mary , who is in a jail cell on a high floor . wheeler and grable sing to each other through the bars . \n",
       "\n",
       " \" the nitwits \" has a few laughs , but the level of comedy is best illustrated by woolsey 's line : \" sonny , you 've got the brain of a six - year - old boy . and i 'll bet even he was glad to get rid of it . \" it 's watered - down xxunk did n't use the superfluous \" even \" when he said it ., Text xxbos this film has the guts to suggest that it might be best to simply accept your life as it is , and keep smiling anyway . as one who is more excited by the idea of taking charge of one 's life and moving forward , i felt slapped in the face , but that 's okay : i do n't have to agree with a movie to love it and respect it . great acting by streep and hurt , and everyone else really , and some wonderfully quirky scenes . a serious film . and take a hanky .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60004, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "      (3): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f40b2b92080>, metrics=[<function accuracy at 0x7f40b41b2730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/farzin/rnn_python_code/wiki103_from_download/clas'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos another trashy grade z quickie from the prolific albert pyun . tim xxunk 13 inch clint eastwood - like cop from outer space chases an ugly flying head ( ! ) to earth and gets involved in a gang war in south bronx ! mercifully short , but xxunk dull , with the cheesiest effects since attack of the 50 ft woman . they should have fired the continuity guy , too : note how xxunk sunglasses disappears and reappears in every second shot . laughably bad , but that´s why we watch these movies , xxunk it ? sequel ´ dollman vs. demonic toys ´ is reportedly even worse , if that´s possible . \n",
       "\n",
       " 0 ( of xxrep 4 * ) \n",
       "\n",
       ", Text xxbos this show stinks . for parents , they usually want their kids to watch something good for them . it is usually educational , funny , and bright . \n",
       "\n",
       " is it educational ? no . the doodlebops sing and that 's it . they usually sing about themselves , they do n't try teaching anything . \n",
       "\n",
       " is it funny ? no . the doodlebops instead say something which is not intended as a joke , and laugh at it . \n",
       "\n",
       " is it bright ? it 's so bright , it 's painful . as far as color , s everything is extremely bright , so that 's good . but xxup nothing is ever wrong in the world of the xxunk 's . therefore , they are always happy . a kid in trouble will become depressed because they have never been exposed to being sad . \n",
       "\n",
       " the show is also extremely cheesy . every syllable is said to the highest level of exaggeration and very corny . it 's overkill . \n",
       "\n",
       " for kids , it 's entertaining , but past the age of 2 you wo n't want your kids to see it . they 'll never know how to grow up ., Text xxbos just two comments xxrep 4 . xxup seven years apart ? hardly evidence of the film 's relentless pulling - power ! as has been mentioned , the low - budget telemovie status of 13 xxup gantry xxup row is a mitigating factor in its limited appeal . having said that however the thing is not without merit - either as entertainment or as a fright outing per se . \n",
       "\n",
       " true , the plot at its most basic is a re - working of xxup the xxup amityville xxup horror - only without much horror . more a case of intrigue ! gibney might have made a more worthwhile impression if she had played xxunk xxunk a couple of seemingly unconnected murders with the \" house \" as the main suspect . the script is better than average and the production overall of a high standard . it just fails to engage the viewer particularly at key moments . \n",
       "\n",
       " having picked the xxup dvd up for a mere $ xxunk last week at my regular video store , i can not begrudge the expenditure . $ xxunk would be an acceptable price for the film . just do n't expect fireworks !, Text xxbos xxup some xxup not - so- xxup xxunk xxup spoilers xxup ahead \n",
       "\n",
       " why do people , when they are disoriented or sick or scared at a club , cut through the middle of the crowded dance floor on their way to the bathroom ? \n",
       "\n",
       " who in their right mind would hide under a bed when someone breaks into their room ? \n",
       "\n",
       " how often do you knock on a stranger 's door and when they do n't xxup immediately answer , you open the door , walk in , shout a few hello 's and then start going through their stuff ? \n",
       "\n",
       " if you were being pursued by someone you just discovered was a murderer , what would you do ? quietly sneak off and hide under a wooden platform or among metal implements ? run , quietly of course , to a ratty old barn or other decrepit structure ? \n",
       "\n",
       " i could be talking about almost any thriller that 's come out in the last few years , but since this is the \" the return \" page , obviously i 'm talking about \" the return . \" i saw it free because i work at a movie theater and make a point of screening all the \" scary \" movies . i thought this one was tolerable ... aside from the well - worn clichés . sarah michelle gellar is really drab and looks kind of \" huh ? \" through most of the film . the details of the plot are slowly given out as the movie progresses and it 's almost enough to make it interesting except there was n't enough explanation as it moved on and so i was almost lost until the last 2 / 3 of it . \n",
       "\n",
       " if you 're a die - hard thriller fan , it 's worth seeing at least once . if there 's nothing better at the theater and you really want to watch a movie , eh , i guess it 's worth a matinée ticket . if you thought the trailer made it look like an interesting movie and you ca n't wait ... wait ., Text xxbos this is a very funny movie , easy to watch , that entertains you almost all the time . the work of the director is recognizable and the type of humor is his trademark . the movie is a typical police partners history like lethal weapon , but the jokes and comedy are of argentinian sort . the twist is that one of them is a psychologist played by peretti and has to go with detective diaz ( played by luque ) on his assignments while he also assist him ( diaz is troubled because his wife cheated on him ) . some of the dialogs are hilarious worldwide : understandable and laughable anywhere . is very good overall , it would deserved an 8 , but i rated 7 because it gets a little down at the end . on a personal remark i must add that is a \" bravo \" for argentinian filmmakers , considering the little good is coming lately .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos i thought it will be a ok movie after seeing the commercials about it . it was funny at some parts and some very nasty . the only person i felt sorry for is horatio sans who got a hot wife who is cheating on him with other women . but he never got a chance to have a threesome with until the and that was good but they should have made more bigger thru out the film ., Text xxbos i enjoyed carax 's \" les amants du pont neuf \" and was therefore expecting this film to be of a similar standard . well , the first 10 minutes were ok , but then it disintegrates into a rather pretentious journey of a young man looking for the essence of life . a sad disappointment ., Text xxbos what 's the matter with you people ? john dahl ? from \" rounders \" and \" unforgettable \" ? xxup too quirky ? knocking emma thompson and alan rickman for having fun playing against type ? and somebody liked the gingerbread man ? \n",
       "\n",
       " i rented this not knowing anything about it and found it about as nifty a video find as you can get . never insulting , well thought out , funny , scary . i disagree with the naysayers , clearly . i thought the story itself was unremarkable but the great cast , which most likely means the director was paying attention , lifted it to super cool status . good sound design also ( much more appreciated in surround , but i 'm not bragging ) . and yes , i 'm a girl , so maybe it has a slight female slant ( the guys in the gang are pretty worthwhile ) . all in all , a 9 and a hearty xxup recommend ., Text xxbos johnnie ( bert wheeler ) is a would - be songwriter ; newton ( robert woolsey ) is a would - be inventor . both work at a cigar stand in the lobby of an office building . johnnie wants to sell a song to winfield lake , a song publisher who also owns the building . lake 's secretary , mary ( betty grable ) , is johnnie 's sweetheart . when lake turns up dead , circumstances conspire to make mary and newton think that johnnie is the killer . they conspire again to implicate mary , who goes to jail . but who really shot lake ? who is the black widow , the blackmailer who had threatened him ? the other characters in this wacky murder mystery are : lake 's suspicious wife , a self - satisfied private detective , a seemingly slow - witted janitor ( willie best ) , lake 's auditor , a songwriter who thinks lake is stealing from him and another who thinks everyone is stealing from him . it 's up to newton and his truth machine to reveal the real killer . \n",
       "\n",
       " the baby - voiced wheeler and the cigar - chomping woolsey strike me as an arbitrary pairing , but they made several movies together in the 30s and some of them were funny . \n",
       "\n",
       " not this one . george stevens , who went on to have a distinguished career , directed this dismal comedy with a tedious murder mystery plot . but two scenes are good , and both feature wheeler and betty grable singing the excellent \" music in my heart , \" written by dorothy fields and jimmy mchugh . the first time , they sing it walking up a staircase ( after which they dance back down ) . later , wheeler and woolsey are on stilts so that they can see and talk to mary , who is in a jail cell on a high floor . wheeler and grable sing to each other through the bars . \n",
       "\n",
       " \" the nitwits \" has a few laughs , but the level of comedy is best illustrated by woolsey 's line : \" sonny , you 've got the brain of a six - year - old boy . and i 'll bet even he was glad to get rid of it . \" it 's watered - down xxunk did n't use the superfluous \" even \" when he said it ., Text xxbos this film has the guts to suggest that it might be best to simply accept your life as it is , and keep smiling anyway . as one who is more excited by the idea of taking charge of one 's life and moving forward , i felt slapped in the face , but that 's okay : i do n't have to agree with a movie to love it and respect it . great acting by streep and hurt , and everyone else really , and some wonderfully quirky scenes . a serious film . and take a hanky .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60004, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "      (3): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f40b2b92080>, metrics=[<function accuracy at 0x7f40b41b2730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/farzin/rnn_python_code/wiki103_from_download/clas'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])\n",
       "bptt: 140\n",
       "alpha: 2.0\n",
       "beta: 1.0\n",
       "adjust: False], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_cls.load('third_FL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 17:49 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.001174</th>\n",
       "    <th>0.000905</th>\n",
       "    <th>0.937040</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.001196</th>\n",
       "    <th>0.002835</th>\n",
       "    <th>0.934200</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.001240</th>\n",
       "    <th>0.001111</th>\n",
       "    <th>0.922680</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.001220</th>\n",
       "    <th>0.001715</th>\n",
       "    <th>0.936200</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.001145</th>\n",
       "    <th>0.003396</th>\n",
       "    <th>0.937120</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.001128</th>\n",
       "    <th>0.001309</th>\n",
       "    <th>0.929960</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.001098</th>\n",
       "    <th>0.001614</th>\n",
       "    <th>0.938920</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.001044</th>\n",
       "    <th>0.001077</th>\n",
       "    <th>0.939360</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.000944</th>\n",
       "    <th>0.001018</th>\n",
       "    <th>0.940560</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.000989</th>\n",
       "    <th>0.001043</th>\n",
       "    <th>0.939720</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.freeze_to(-3)\n",
    "learn_cls.fit_one_cycle(10, slice(2e-2/(2.6**2),0.5e-2), moms=(0.8,0.7), pct_start=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 17:50 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.001006</th>\n",
       "    <th>0.001035</th>\n",
       "    <th>0.932560</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.001312</th>\n",
       "    <th>0.001208</th>\n",
       "    <th>0.922760</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.001123</th>\n",
       "    <th>0.045645</th>\n",
       "    <th>0.935200</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.001225</th>\n",
       "    <th>0.001308</th>\n",
       "    <th>0.935320</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.001143</th>\n",
       "    <th>0.001212</th>\n",
       "    <th>0.937600</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.001015</th>\n",
       "    <th>0.001129</th>\n",
       "    <th>0.938520</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.001104</th>\n",
       "    <th>0.001184</th>\n",
       "    <th>0.938560</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.000975</th>\n",
       "    <th>0.001963</th>\n",
       "    <th>0.939840</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.000869</th>\n",
       "    <th>0.001018</th>\n",
       "    <th>0.940840</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.000872</th>\n",
       "    <th>0.001138</th>\n",
       "    <th>0.942040</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.freeze_to(-3)\n",
    "learn_cls.fit_one_cycle(10, slice(2e-2/(2.6**2),0.5e-2), moms=(0.8,0.7), pct_start=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 10:41 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.000831</th>\n",
       "    <th>0.000909</th>\n",
       "    <th>0.939440</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.000910</th>\n",
       "    <th>0.001380</th>\n",
       "    <th>0.940200</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.000729</th>\n",
       "    <th>0.001617</th>\n",
       "    <th>0.941680</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.000885</th>\n",
       "    <th>0.001104</th>\n",
       "    <th>0.943560</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.unfreeze()\n",
    "learn_cls.fit_one_cycle(4, slice(0.5e-2/(2.6**4),0.25e-2), moms=(0.8,0.7), pct_start=0.1) #, wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 26:38 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.000946</th>\n",
       "    <th>0.001049</th>\n",
       "    <th>0.942040</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.000854</th>\n",
       "    <th>0.001057</th>\n",
       "    <th>0.931520</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.000906</th>\n",
       "    <th>0.001126</th>\n",
       "    <th>0.941280</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.000902</th>\n",
       "    <th>0.001153</th>\n",
       "    <th>0.940440</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.000672</th>\n",
       "    <th>0.001010</th>\n",
       "    <th>0.938960</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.000642</th>\n",
       "    <th>0.001117</th>\n",
       "    <th>0.941120</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.000608</th>\n",
       "    <th>0.001017</th>\n",
       "    <th>0.938160</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.000500</th>\n",
       "    <th>0.001031</th>\n",
       "    <th>0.941800</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.000460</th>\n",
       "    <th>0.001152</th>\n",
       "    <th>0.939520</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.000523</th>\n",
       "    <th>0.001112</th>\n",
       "    <th>0.940560</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_cls.fit_one_cycle(10, slice(0.75e-2/(2.6**4),0.5e-2), moms=(0.8,0.7), pct_start=0.05) #, wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cls.save('final_FL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learn_cls\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate mis-labeled cases in train set. \n",
    "Are they marginal reviews?  Other details that could be better addressed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos another trashy grade z quickie from the prolific albert pyun . tim xxunk 13 inch clint eastwood - like cop from outer space chases an ugly flying head ( ! ) to earth and gets involved in a gang war in south bronx ! mercifully short , but xxunk dull , with the cheesiest effects since attack of the 50 ft woman . they should have fired the continuity guy , too : note how xxunk sunglasses disappears and reappears in every second shot . laughably bad , but that´s why we watch these movies , xxunk it ? sequel ´ dollman vs. demonic toys ´ is reportedly even worse , if that´s possible . \n",
       "\n",
       " 0 ( of xxrep 4 * ) \n",
       "\n",
       ", Text xxbos this show stinks . for parents , they usually want their kids to watch something good for them . it is usually educational , funny , and bright . \n",
       "\n",
       " is it educational ? no . the doodlebops sing and that 's it . they usually sing about themselves , they do n't try teaching anything . \n",
       "\n",
       " is it funny ? no . the doodlebops instead say something which is not intended as a joke , and laugh at it . \n",
       "\n",
       " is it bright ? it 's so bright , it 's painful . as far as color , s everything is extremely bright , so that 's good . but xxup nothing is ever wrong in the world of the xxunk 's . therefore , they are always happy . a kid in trouble will become depressed because they have never been exposed to being sad . \n",
       "\n",
       " the show is also extremely cheesy . every syllable is said to the highest level of exaggeration and very corny . it 's overkill . \n",
       "\n",
       " for kids , it 's entertaining , but past the age of 2 you wo n't want your kids to see it . they 'll never know how to grow up ., Text xxbos just two comments xxrep 4 . xxup seven years apart ? hardly evidence of the film 's relentless pulling - power ! as has been mentioned , the low - budget telemovie status of 13 xxup gantry xxup row is a mitigating factor in its limited appeal . having said that however the thing is not without merit - either as entertainment or as a fright outing per se . \n",
       "\n",
       " true , the plot at its most basic is a re - working of xxup the xxup amityville xxup horror - only without much horror . more a case of intrigue ! gibney might have made a more worthwhile impression if she had played xxunk xxunk a couple of seemingly unconnected murders with the \" house \" as the main suspect . the script is better than average and the production overall of a high standard . it just fails to engage the viewer particularly at key moments . \n",
       "\n",
       " having picked the xxup dvd up for a mere $ xxunk last week at my regular video store , i can not begrudge the expenditure . $ xxunk would be an acceptable price for the film . just do n't expect fireworks !, Text xxbos xxup some xxup not - so- xxup xxunk xxup spoilers xxup ahead \n",
       "\n",
       " why do people , when they are disoriented or sick or scared at a club , cut through the middle of the crowded dance floor on their way to the bathroom ? \n",
       "\n",
       " who in their right mind would hide under a bed when someone breaks into their room ? \n",
       "\n",
       " how often do you knock on a stranger 's door and when they do n't xxup immediately answer , you open the door , walk in , shout a few hello 's and then start going through their stuff ? \n",
       "\n",
       " if you were being pursued by someone you just discovered was a murderer , what would you do ? quietly sneak off and hide under a wooden platform or among metal implements ? run , quietly of course , to a ratty old barn or other decrepit structure ? \n",
       "\n",
       " i could be talking about almost any thriller that 's come out in the last few years , but since this is the \" the return \" page , obviously i 'm talking about \" the return . \" i saw it free because i work at a movie theater and make a point of screening all the \" scary \" movies . i thought this one was tolerable ... aside from the well - worn clichés . sarah michelle gellar is really drab and looks kind of \" huh ? \" through most of the film . the details of the plot are slowly given out as the movie progresses and it 's almost enough to make it interesting except there was n't enough explanation as it moved on and so i was almost lost until the last 2 / 3 of it . \n",
       "\n",
       " if you 're a die - hard thriller fan , it 's worth seeing at least once . if there 's nothing better at the theater and you really want to watch a movie , eh , i guess it 's worth a matinée ticket . if you thought the trailer made it look like an interesting movie and you ca n't wait ... wait ., Text xxbos this is a very funny movie , easy to watch , that entertains you almost all the time . the work of the director is recognizable and the type of humor is his trademark . the movie is a typical police partners history like lethal weapon , but the jokes and comedy are of argentinian sort . the twist is that one of them is a psychologist played by peretti and has to go with detective diaz ( played by luque ) on his assignments while he also assist him ( diaz is troubled because his wife cheated on him ) . some of the dialogs are hilarious worldwide : understandable and laughable anywhere . is very good overall , it would deserved an 8 , but i rated 7 because it gets a little down at the end . on a personal remark i must add that is a \" bravo \" for argentinian filmmakers , considering the little good is coming lately .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos i thought it will be a ok movie after seeing the commercials about it . it was funny at some parts and some very nasty . the only person i felt sorry for is horatio sans who got a hot wife who is cheating on him with other women . but he never got a chance to have a threesome with until the and that was good but they should have made more bigger thru out the film ., Text xxbos i enjoyed carax 's \" les amants du pont neuf \" and was therefore expecting this film to be of a similar standard . well , the first 10 minutes were ok , but then it disintegrates into a rather pretentious journey of a young man looking for the essence of life . a sad disappointment ., Text xxbos what 's the matter with you people ? john dahl ? from \" rounders \" and \" unforgettable \" ? xxup too quirky ? knocking emma thompson and alan rickman for having fun playing against type ? and somebody liked the gingerbread man ? \n",
       "\n",
       " i rented this not knowing anything about it and found it about as nifty a video find as you can get . never insulting , well thought out , funny , scary . i disagree with the naysayers , clearly . i thought the story itself was unremarkable but the great cast , which most likely means the director was paying attention , lifted it to super cool status . good sound design also ( much more appreciated in surround , but i 'm not bragging ) . and yes , i 'm a girl , so maybe it has a slight female slant ( the guys in the gang are pretty worthwhile ) . all in all , a 9 and a hearty xxup recommend ., Text xxbos johnnie ( bert wheeler ) is a would - be songwriter ; newton ( robert woolsey ) is a would - be inventor . both work at a cigar stand in the lobby of an office building . johnnie wants to sell a song to winfield lake , a song publisher who also owns the building . lake 's secretary , mary ( betty grable ) , is johnnie 's sweetheart . when lake turns up dead , circumstances conspire to make mary and newton think that johnnie is the killer . they conspire again to implicate mary , who goes to jail . but who really shot lake ? who is the black widow , the blackmailer who had threatened him ? the other characters in this wacky murder mystery are : lake 's suspicious wife , a self - satisfied private detective , a seemingly slow - witted janitor ( willie best ) , lake 's auditor , a songwriter who thinks lake is stealing from him and another who thinks everyone is stealing from him . it 's up to newton and his truth machine to reveal the real killer . \n",
       "\n",
       " the baby - voiced wheeler and the cigar - chomping woolsey strike me as an arbitrary pairing , but they made several movies together in the 30s and some of them were funny . \n",
       "\n",
       " not this one . george stevens , who went on to have a distinguished career , directed this dismal comedy with a tedious murder mystery plot . but two scenes are good , and both feature wheeler and betty grable singing the excellent \" music in my heart , \" written by dorothy fields and jimmy mchugh . the first time , they sing it walking up a staircase ( after which they dance back down ) . later , wheeler and woolsey are on stilts so that they can see and talk to mary , who is in a jail cell on a high floor . wheeler and grable sing to each other through the bars . \n",
       "\n",
       " \" the nitwits \" has a few laughs , but the level of comedy is best illustrated by woolsey 's line : \" sonny , you 've got the brain of a six - year - old boy . and i 'll bet even he was glad to get rid of it . \" it 's watered - down xxunk did n't use the superfluous \" even \" when he said it ., Text xxbos this film has the guts to suggest that it might be best to simply accept your life as it is , and keep smiling anyway . as one who is more excited by the idea of taking charge of one 's life and moving forward , i felt slapped in the face , but that 's okay : i do n't have to agree with a movie to love it and respect it . great acting by streep and hurt , and everyone else really , and some wonderfully quirky scenes . a serious film . and take a hanky .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60004, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "      (3): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f40b2b92080>, metrics=[<function accuracy at 0x7f40b41b2730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/farzin/rnn_python_code/wiki103_from_download/clas'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos another trashy grade z quickie from the prolific albert pyun . tim xxunk 13 inch clint eastwood - like cop from outer space chases an ugly flying head ( ! ) to earth and gets involved in a gang war in south bronx ! mercifully short , but xxunk dull , with the cheesiest effects since attack of the 50 ft woman . they should have fired the continuity guy , too : note how xxunk sunglasses disappears and reappears in every second shot . laughably bad , but that´s why we watch these movies , xxunk it ? sequel ´ dollman vs. demonic toys ´ is reportedly even worse , if that´s possible . \n",
       "\n",
       " 0 ( of xxrep 4 * ) \n",
       "\n",
       ", Text xxbos this show stinks . for parents , they usually want their kids to watch something good for them . it is usually educational , funny , and bright . \n",
       "\n",
       " is it educational ? no . the doodlebops sing and that 's it . they usually sing about themselves , they do n't try teaching anything . \n",
       "\n",
       " is it funny ? no . the doodlebops instead say something which is not intended as a joke , and laugh at it . \n",
       "\n",
       " is it bright ? it 's so bright , it 's painful . as far as color , s everything is extremely bright , so that 's good . but xxup nothing is ever wrong in the world of the xxunk 's . therefore , they are always happy . a kid in trouble will become depressed because they have never been exposed to being sad . \n",
       "\n",
       " the show is also extremely cheesy . every syllable is said to the highest level of exaggeration and very corny . it 's overkill . \n",
       "\n",
       " for kids , it 's entertaining , but past the age of 2 you wo n't want your kids to see it . they 'll never know how to grow up ., Text xxbos just two comments xxrep 4 . xxup seven years apart ? hardly evidence of the film 's relentless pulling - power ! as has been mentioned , the low - budget telemovie status of 13 xxup gantry xxup row is a mitigating factor in its limited appeal . having said that however the thing is not without merit - either as entertainment or as a fright outing per se . \n",
       "\n",
       " true , the plot at its most basic is a re - working of xxup the xxup amityville xxup horror - only without much horror . more a case of intrigue ! gibney might have made a more worthwhile impression if she had played xxunk xxunk a couple of seemingly unconnected murders with the \" house \" as the main suspect . the script is better than average and the production overall of a high standard . it just fails to engage the viewer particularly at key moments . \n",
       "\n",
       " having picked the xxup dvd up for a mere $ xxunk last week at my regular video store , i can not begrudge the expenditure . $ xxunk would be an acceptable price for the film . just do n't expect fireworks !, Text xxbos xxup some xxup not - so- xxup xxunk xxup spoilers xxup ahead \n",
       "\n",
       " why do people , when they are disoriented or sick or scared at a club , cut through the middle of the crowded dance floor on their way to the bathroom ? \n",
       "\n",
       " who in their right mind would hide under a bed when someone breaks into their room ? \n",
       "\n",
       " how often do you knock on a stranger 's door and when they do n't xxup immediately answer , you open the door , walk in , shout a few hello 's and then start going through their stuff ? \n",
       "\n",
       " if you were being pursued by someone you just discovered was a murderer , what would you do ? quietly sneak off and hide under a wooden platform or among metal implements ? run , quietly of course , to a ratty old barn or other decrepit structure ? \n",
       "\n",
       " i could be talking about almost any thriller that 's come out in the last few years , but since this is the \" the return \" page , obviously i 'm talking about \" the return . \" i saw it free because i work at a movie theater and make a point of screening all the \" scary \" movies . i thought this one was tolerable ... aside from the well - worn clichés . sarah michelle gellar is really drab and looks kind of \" huh ? \" through most of the film . the details of the plot are slowly given out as the movie progresses and it 's almost enough to make it interesting except there was n't enough explanation as it moved on and so i was almost lost until the last 2 / 3 of it . \n",
       "\n",
       " if you 're a die - hard thriller fan , it 's worth seeing at least once . if there 's nothing better at the theater and you really want to watch a movie , eh , i guess it 's worth a matinée ticket . if you thought the trailer made it look like an interesting movie and you ca n't wait ... wait ., Text xxbos this is a very funny movie , easy to watch , that entertains you almost all the time . the work of the director is recognizable and the type of humor is his trademark . the movie is a typical police partners history like lethal weapon , but the jokes and comedy are of argentinian sort . the twist is that one of them is a psychologist played by peretti and has to go with detective diaz ( played by luque ) on his assignments while he also assist him ( diaz is troubled because his wife cheated on him ) . some of the dialogs are hilarious worldwide : understandable and laughable anywhere . is very good overall , it would deserved an 8 , but i rated 7 because it gets a little down at the end . on a personal remark i must add that is a \" bravo \" for argentinian filmmakers , considering the little good is coming lately .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (25000 items)\n",
       "[Category 0, Category 0, Category 1, Category 0, Category 1]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas\n",
       "x: TextList (25000 items)\n",
       "[Text xxbos i thought it will be a ok movie after seeing the commercials about it . it was funny at some parts and some very nasty . the only person i felt sorry for is horatio sans who got a hot wife who is cheating on him with other women . but he never got a chance to have a threesome with until the and that was good but they should have made more bigger thru out the film ., Text xxbos i enjoyed carax 's \" les amants du pont neuf \" and was therefore expecting this film to be of a similar standard . well , the first 10 minutes were ok , but then it disintegrates into a rather pretentious journey of a young man looking for the essence of life . a sad disappointment ., Text xxbos what 's the matter with you people ? john dahl ? from \" rounders \" and \" unforgettable \" ? xxup too quirky ? knocking emma thompson and alan rickman for having fun playing against type ? and somebody liked the gingerbread man ? \n",
       "\n",
       " i rented this not knowing anything about it and found it about as nifty a video find as you can get . never insulting , well thought out , funny , scary . i disagree with the naysayers , clearly . i thought the story itself was unremarkable but the great cast , which most likely means the director was paying attention , lifted it to super cool status . good sound design also ( much more appreciated in surround , but i 'm not bragging ) . and yes , i 'm a girl , so maybe it has a slight female slant ( the guys in the gang are pretty worthwhile ) . all in all , a 9 and a hearty xxup recommend ., Text xxbos johnnie ( bert wheeler ) is a would - be songwriter ; newton ( robert woolsey ) is a would - be inventor . both work at a cigar stand in the lobby of an office building . johnnie wants to sell a song to winfield lake , a song publisher who also owns the building . lake 's secretary , mary ( betty grable ) , is johnnie 's sweetheart . when lake turns up dead , circumstances conspire to make mary and newton think that johnnie is the killer . they conspire again to implicate mary , who goes to jail . but who really shot lake ? who is the black widow , the blackmailer who had threatened him ? the other characters in this wacky murder mystery are : lake 's suspicious wife , a self - satisfied private detective , a seemingly slow - witted janitor ( willie best ) , lake 's auditor , a songwriter who thinks lake is stealing from him and another who thinks everyone is stealing from him . it 's up to newton and his truth machine to reveal the real killer . \n",
       "\n",
       " the baby - voiced wheeler and the cigar - chomping woolsey strike me as an arbitrary pairing , but they made several movies together in the 30s and some of them were funny . \n",
       "\n",
       " not this one . george stevens , who went on to have a distinguished career , directed this dismal comedy with a tedious murder mystery plot . but two scenes are good , and both feature wheeler and betty grable singing the excellent \" music in my heart , \" written by dorothy fields and jimmy mchugh . the first time , they sing it walking up a staircase ( after which they dance back down ) . later , wheeler and woolsey are on stilts so that they can see and talk to mary , who is in a jail cell on a high floor . wheeler and grable sing to each other through the bars . \n",
       "\n",
       " \" the nitwits \" has a few laughs , but the level of comedy is best illustrated by woolsey 's line : \" sonny , you 've got the brain of a six - year - old boy . and i 'll bet even he was glad to get rid of it . \" it 's watered - down xxunk did n't use the superfluous \" even \" when he said it ., Text xxbos this film has the guts to suggest that it might be best to simply accept your life as it is , and keep smiling anyway . as one who is more excited by the idea of taking charge of one 's life and moving forward , i felt slapped in the face , but that 's okay : i do n't have to agree with a movie to love it and respect it . great acting by streep and hurt , and everyone else really , and some wonderfully quirky scenes . a serious film . and take a hanky .]...\n",
       "Path: /home/farzin/rnn_python_code/wiki103_from_download/clas;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60004, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60004, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): QRNNLayer(\n",
       "        (linear): WeightDropout(\n",
       "          (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "      (3): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f40b2b92080>, metrics=[<function accuracy at 0x7f40b41b2730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/farzin/rnn_python_code/wiki103_from_download/clas'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])\n",
       "bptt: 140\n",
       "alpha: 2.0\n",
       "beta: 1.0\n",
       "adjust: False], layer_groups=[Sequential(\n",
       "  (0): Embedding(60004, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60004, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=800, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=3333, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): QRNNLayer(\n",
       "    (linear): WeightDropout(\n",
       "      (module): Linear(in_features=1111, out_features=1200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_cls.load('final')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How to check that this works properly with the train data and the test data?\n",
    "What is the smallest example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetType.Fix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_hat, y_true = learn_cls.get_preds(DatasetType.Fix,ordered=True)\n",
    "trn_df = CLS_train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, y_true = learn_cls.get_preds(DatasetType.Valid,ordered=True)\n",
    "trn_df = CLS_valid_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = F.softmax(y_hat,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df['pred0'] = to_np(y_hat)[:,0]\n",
    "trn_df['pred1'] = to_np(y_hat)[:,1]\n",
    "trn_df['pred_label']= to_np(y_hat).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_np(y_true)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.labels.values[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>pred0</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I thought it will be a Ok movie after seeing t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578663</td>\n",
       "      <td>0.421337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I enjoyed Carax's \"Les Amants du Pont Neuf\" an...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992695</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>What's the matter with you people? John Dahl? ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.985571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Johnnie (Bert Wheeler) is a would-be songwrite...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.993896</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This film has the guts to suggest that it migh...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>0.995605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text  rating  \\\n",
       "0       0  I thought it will be a Ok movie after seeing t...       1   \n",
       "1       0  I enjoyed Carax's \"Les Amants du Pont Neuf\" an...       4   \n",
       "2       1  What's the matter with you people? John Dahl? ...      10   \n",
       "3       0  Johnnie (Bert Wheeler) is a would-be songwrite...       3   \n",
       "4       1  This film has the guts to suggest that it migh...       8   \n",
       "\n",
       "      pred0     pred1  pred_label  \n",
       "0  0.578663  0.421337           0  \n",
       "1  0.992695  0.007305           0  \n",
       "2  0.014429  0.985571           1  \n",
       "3  0.993896  0.006104           0  \n",
       "4  0.004395  0.995605           1  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, many of the marginal ratings (4 & 7) are a greater % of the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.-(trn_df.pred_label != trn_df.labels).sum()/len(trn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     142\n",
       "2      95\n",
       "3     152\n",
       "4     337\n",
       "7     318\n",
       "8     180\n",
       "9     107\n",
       "10    204\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df[trn_df.pred_label != trn_df.labels].rating.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.028276\n",
       "2     0.041268\n",
       "3     0.059819\n",
       "4     0.127894\n",
       "7     0.137841\n",
       "8     0.063158\n",
       "9     0.045648\n",
       "10    0.040808\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df[trn_df.pred_label != trn_df.labels].rating.value_counts().sort_index() / trn_df.rating.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble with forward/backward Preds averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd_trn_df = pd.read_csv('bwd_training_classification.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>pred0</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I thought it will be a Ok movie after seeing t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906678</td>\n",
       "      <td>0.093322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I enjoyed Carax's \"Les Amants du Pont Neuf\" an...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994287</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>What's the matter with you people? John Dahl? ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.983535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Johnnie (Bert Wheeler) is a would-be songwrite...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.898954</td>\n",
       "      <td>0.101046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This film has the guts to suggest that it migh...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.997573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text  rating  \\\n",
       "0       0  I thought it will be a Ok movie after seeing t...       1   \n",
       "1       0  I enjoyed Carax's \"Les Amants du Pont Neuf\" an...       4   \n",
       "2       1  What's the matter with you people? John Dahl? ...      10   \n",
       "3       0  Johnnie (Bert Wheeler) is a would-be songwrite...       3   \n",
       "4       1  This film has the guts to suggest that it migh...       8   \n",
       "\n",
       "      pred0     pred1  pred_label  \n",
       "0  0.906678  0.093322           0  \n",
       "1  0.994287  0.005713           0  \n",
       "2  0.016465  0.983535           1  \n",
       "3  0.898954  0.101046           0  \n",
       "4  0.002427  0.997573           1  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwd_trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df['ens0'] = 0.5*(bwd_trn_df['pred0']+trn_df['pred0'])\n",
    "trn_df['ens1'] = 0.5*(bwd_trn_df['pred1']+trn_df['pred1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df['ens_pred'] = trn_df[['ens0','ens1']].values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94084"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.-(trn_df.ens_pred != trn_df.labels).sum()/len(trn_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 fasta.ai1 DEV",
   "language": "python",
   "name": "fastai1_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
